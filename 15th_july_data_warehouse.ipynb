{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493bf9b3",
   "metadata": {},
   "source": [
    "# TOPIC: Data Warehousing Fundamentals\n",
    "   1. Design a data warehouse schema for a retail company that includes dimension tables for products, customers, and time. Implement the schema using a relational database management system (RDBMS) of your choice.\n",
    "   2. Create a fact table that captures sales data, including product ID, customer ID, date, and sales amount. Populate the fact table with sample data.\n",
    "   3. Write SQL queries to retrieve sales data from the data warehouse, including aggregations and filtering based on different dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be29b9c",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Let's go through each step to design the data warehouse schema, create the fact table, and write SQL queries to retrieve sales data.\n",
    "\n",
    "Designing the Data Warehouse Schema:\n",
    "For the retail company, we will create the following dimension tables: products, customers, and time.\n",
    "\n",
    "Products Dimension Table:\n",
    "\n",
    "**product_id (primary key)**\n",
    "product_name,\n",
    "category,\n",
    "price,\n",
    "... (other relevant product attributes)\n",
    "Customers Dimension Table:\n",
    "\n",
    "**customer_id (primary key)**\n",
    "customer_name,\n",
    "address,\n",
    "email,\n",
    "... (other relevant customer attributes)\n",
    "Time Dimension Table:\n",
    "\n",
    "**date_id (primary key)**\n",
    "date,\n",
    "day,\n",
    "month,\n",
    "year,\n",
    "... (other relevant time attributes)\n",
    "Creating the Fact Table and Populating it with Sample Data:\n",
    "Let's create a fact table called \"sales\" to capture sales data. The fact table will contain the following columns:\n",
    "\n",
    "**sales_id (primary key)**\n",
    "product_id (foreign key referencing the products dimension table)\n",
    "customer_id (foreign key referencing the customers dimension table)\n",
    "date_id (foreign key referencing the time dimension table)\n",
    "sales_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcd586",
   "metadata": {},
   "source": [
    "**Creating the Fact Table and Populating it with Sample Data:\n",
    "Let's create a fact table called \"sales\" to capture sales data. The fact table will contain the following columns:**\n",
    "\n",
    "sales_id (primary key)\n",
    "\n",
    "product_id (foreign key referencing the products dimension table)\n",
    "\n",
    "customer_id (foreign key referencing the customers dimension table)\n",
    "\n",
    "date_id (foreign key referencing the time dimension table)\n",
    "\n",
    "sales_amount "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05640b",
   "metadata": {},
   "source": [
    "**Writing SQL Queries to Retrieve Sales Data:\n",
    "Here are some sample SQL queries to retrieve sales data from the data warehouse:**\n",
    "\n",
    "**a. Retrieve total sales amount for each product:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1b919",
   "metadata": {},
   "source": [
    "SELECT p.product_name, SUM(s.sales_amount) AS total_sales\n",
    "FROM sales s\n",
    "\n",
    "INNER JOIN products p ON s.product_id = p.product_id\n",
    "\n",
    "GROUP BY p.product_name;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39bd3d",
   "metadata": {},
   "source": [
    "**b. Retrieve total sales amount for each customer:**\n",
    "\n",
    "SELECT c.customer_name, SUM(s.sales_amount) AS total_sales\n",
    "\n",
    "FROM sales s\n",
    "\n",
    "INNER JOIN customers c ON s.customer_id = c.customer_id\n",
    "GROUP BY c.customer_name;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f1209",
   "metadata": {},
   "source": [
    "**c. Retrieve total sales amount for each month:**\n",
    "    \n",
    "    SELECT t.month, SUM(s.sales_amount) AS total_sales\n",
    "    \n",
    "    FROM sales s\n",
    "    \n",
    "    INNER JOIN time t ON s.date_id = t.date_id\n",
    "    GROUP BY t.month;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455687e",
   "metadata": {},
   "source": [
    "**d. Retrieve sales amount for a specific product and customer:**\n",
    "    \n",
    "    SELECT p.product_name, c.customer_name, s.sales_amount\n",
    "    \n",
    "    FROM sales s\n",
    "    INNER JOIN products p ON s.product_id = p.product_id\n",
    "    INNER JOIN customers c ON s.customer_id = c.customer_id\n",
    "    WHERE p.product_name = 'ProductA' AND c.customer_name = 'CustomerX';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40d66b",
   "metadata": {},
   "source": [
    "# TOPIC: ETL and Data Integration\n",
    "  1. Design an ETL process using a programming language (e.g., Python) to extract data from a source system (e.g., CSV files), transform it by applying certain business rules or calculations, and load it into a data warehouse.\n",
    "  2. Implement the ETL process by writing code that performs the extraction, transformation, and loading steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dfd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2  # Assuming PostgreSQL as the data warehouse\n",
    "\n",
    "# Extraction Step\n",
    "def extract_data(csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return list(reader)\n",
    "\n",
    "# Transformation Step\n",
    "def transform_data(data):\n",
    "    transformed_data = []\n",
    "    for row in data:\n",
    "        # Apply business rules or calculations here\n",
    "        # Example: Calculate total price by multiplying quantity and unit price\n",
    "        total_price = float(row['quantity']) * float(row['unit_price'])\n",
    "\n",
    "        transformed_row = {\n",
    "            'product_name': row['product_name'],\n",
    "            'total_price': total_price,\n",
    "            # Add other transformed fields as needed\n",
    "        }\n",
    "        transformed_data.append(transformed_row)\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "# Loading Step\n",
    "def load_data(data):\n",
    "    conn = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    for row in data:\n",
    "        # Assuming a table called 'sales' in the data warehouse\n",
    "        cursor.execute(\"INSERT INTO sales (product_name, total_price) VALUES (%s, %s)\", (row['product_name'], row['total_price']))\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Main ETL process\n",
    "def etl_process(csv_file):\n",
    "    # Extraction\n",
    "    extracted_data = extract_data(csv_file)\n",
    "\n",
    "    # Transformation\n",
    "    transformed_data = transform_data(extracted_data)\n",
    "\n",
    "    # Loading\n",
    "    load_data(transformed_data)\n",
    "\n",
    "# Run the ETL process\n",
    "etl_process('data.csv')  # Replace 'data.csv' with your actual CSV file name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449f4de",
   "metadata": {},
   "source": [
    "# TOPIC: Dimensional Modeling and Schemas\n",
    "   1. Design a star schema for a university database, including a fact table for student enrollments and dimension tables for students, courses, and time. Implement the schema using a database of your choice.\n",
    "   2. Write SQL queries to retrieve data from the star schema, including aggregations and joins between the fact table and dimension tables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae3baa",
   "metadata": {},
   "source": [
    "**Designing the Star Schema:\n",
    "The star schema for the university database will consist of a fact table for student enrollments and dimension tables for students, courses, and time.**\n",
    "\n",
    "**Fact Table: Enrollments**\n",
    "\n",
    "enrollment_id (primary key)\n",
    "\n",
    "student_id (foreign key referencing the Students dimension table)\n",
    "\n",
    "course_id (foreign key referencing the Courses dimension table)\n",
    "\n",
    "time_id (foreign key referencing the Time dimension table)\n",
    "\n",
    "grade\n",
    "\n",
    "... (other relevant enrollment attributes)\n",
    "\n",
    "**Dimension Table: Students**\n",
    "\n",
    "student_id (primary key)\n",
    "\n",
    "student_name\n",
    "\n",
    "date_of_birth\n",
    "\n",
    "major\n",
    "... (other relevant student attributes)\n",
    "\n",
    "**Dimension Table: Courses**\n",
    "\n",
    "course_id (primary key)\n",
    "\n",
    "course_name\n",
    "\n",
    "department\n",
    "\n",
    "instructor\n",
    "\n",
    "... (other relevant course attributes)\n",
    "\n",
    "**Dimension Table: Time**\n",
    "\n",
    "time_id (primary key)\n",
    "\n",
    "date\n",
    "\n",
    "day\n",
    "\n",
    "month\n",
    "\n",
    "year\n",
    "... (other relevant time attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60674df9",
   "metadata": {},
   "source": [
    "** 2. Write SQL queries to retrieve data from the star schema, including aggregations and joins between the fact table and dimension tables.**\n",
    "\n",
    "-- Create the Students dimension table\n",
    "\n",
    "CREATE TABLE Students (\n",
    "    student_id SERIAL PRIMARY KEY,\n",
    "    student_name VARCHAR(100),\n",
    "    date_of_birth DATE,\n",
    "    major VARCHAR(50)\n",
    "    -- Add other student attributes as needed\n",
    ");\n",
    "\n",
    "-- Create the Courses dimension table\n",
    "\n",
    "CREATE TABLE Courses (\n",
    "    course_id SERIAL PRIMARY KEY,\n",
    "    course_name VARCHAR(100),\n",
    "    department VARCHAR(50),\n",
    "    instructor VARCHAR(100)\n",
    "    -- Add other course attributes as needed\n",
    ");\n",
    "\n",
    "-- Create the Time dimension table\n",
    "\n",
    "CREATE TABLE Time (\n",
    "    time_id SERIAL PRIMARY KEY,\n",
    "    date DATE,\n",
    "    day INTEGER,\n",
    "    month INTEGER,\n",
    "    year INTEGER\n",
    "    -- Add other time attributes as needed\n",
    ");\n",
    "\n",
    "-- Create the Enrollments fact table\n",
    "\n",
    "CREATE TABLE Enrollments (\n",
    "    enrollment_id SERIAL PRIMARY KEY,\n",
    "    student_id INTEGER REFERENCES Students(student_id),\n",
    "    course_id INTEGER REFERENCES Courses(course_id),\n",
    "    time_id INTEGER REFERENCES Time(time_id),\n",
    "    grade VARCHAR(2)\n",
    "    -- Add other enrollment attributes as needed\n",
    ");\n",
    "\n",
    "-- Insert sample data into the dimension tables\n",
    "\n",
    "INSERT INTO Students (student_name, date_of_birth, major) VALUES\n",
    "    ('John Smith', '1995-02-15', 'Computer Science'),\n",
    "    ('Jane Doe', '1998-07-03', 'Physics');\n",
    "\n",
    "INSERT INTO Courses (course_name, department, instructor) VALUES\n",
    "    ('Database Management', 'Computer Science', 'Dr. Johnson'),\n",
    "    ('Quantum Mechanics', 'Physics', 'Prof. Williams');\n",
    "\n",
    "INSERT INTO Time (date, day, month, year) VALUES\n",
    "    ('2023-01-01', 1, 1, 2023),\n",
    "    ('2023-02-01', 1, 2, 2023);\n",
    "\n",
    "-- Insert sample data into the Enrollments fact table\n",
    "INSERT INTO Enrollments (student_id, course_id, time_id, grade) VALUES\n",
    "    (1, 1, 1, 'A'),\n",
    "    (2, 2, 2, 'B');\n",
    "\n",
    "-- SQL queries to retrieve data from the star schema\n",
    "\n",
    "-- Retrieve all enrollments with student and course details\n",
    "\n",
    "SELECT e.enrollment_id, s.student_name, c.course_name, e.grade\n",
    "FROM Enrollments e\n",
    "INNER JOIN Students s ON e.student_id = s.student_id\n",
    "INNER JOIN Courses c ON e.course_id = c.course_id;\n",
    "\n",
    "-- Retrieve total enrollments count by department and year\n",
    "\n",
    "SELECT c.department, t.year, COUNT(*) AS enrollments_count\n",
    "FROM Enrollments e\n",
    "INNER JOIN Courses c ON e.course_id = c.course_id\n",
    "INNER JOIN Time t ON e.time_id = t.time_id\n",
    "GROUP BY c.department, t.year;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863b7a3",
   "metadata": {},
   "source": [
    "# **TOPIC: Performance Optimization and Querying**\n",
    "    1. Scenario: You need to improve the performance of your data loading process in the data warehouse. Write a Python script that implements the following optimizations:Utilize batch processing techniques to load data in bulk instead of individual row insertion.\n",
    "      b)  Implement multi-threading or multiprocessing to parallelize the data loading process.\n",
    "      c)  Measure the time taken to load a specific amount of data before and after implementing these optimizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Define your database connection details\n",
    "DB_NAME = \"your_database\"\n",
    "DB_USER = \"your_user\"\n",
    "DB_PASSWORD = \"your_password\"\n",
    "DB_HOST = \"your_host\"\n",
    "DB_PORT = \"your_port\"\n",
    "\n",
    "# Define the number of threads or processes to use\n",
    "NUM_THREADS = 4\n",
    "\n",
    "# Define the batch size for bulk data loading\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "# Function to load data in batches\n",
    "def load_data_batch(batch_data):\n",
    "    conn = psycopg2.connect(\n",
    "        database=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Assuming a table called 'your_table' in the data warehouse\n",
    "    query = \"INSERT INTO your_table (column1, column2, ...) VALUES (%s, %s, ...)\"\n",
    "    cursor.executemany(query, batch_data)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Function to load data using multiprocessing\n",
    "def load_data_multiprocessing(data):\n",
    "    pool = Pool(NUM_THREADS)\n",
    "    pool.map(load_data_batch, data)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "# Function to load data using multi-threading\n",
    "def load_data_multithreading(data):\n",
    "    with Pool(NUM_THREADS) as pool:\n",
    "        pool.map(load_data_batch, data)\n",
    "\n",
    "# Function to measure the time taken to load data\n",
    "def measure_loading_time(data_loading_func, data):\n",
    "    start_time = time.time()\n",
    "    data_loading_func(data)\n",
    "    end_time = time.time()\n",
    "    loading_time = end_time - start_time\n",
    "    print(f\"Time taken to load data: {loading_time} seconds\")\n",
    "\n",
    "# Main data loading process\n",
    "def load_data():\n",
    "    # Read data from CSV file or any other source\n",
    "    with open(\"data.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = [row for row in reader]\n",
    "\n",
    "    # Divide the data into batches\n",
    "    batches = [data[i : i + BATCH_SIZE] for i in range(0, len(data), BATCH_SIZE)]\n",
    "\n",
    "    # Measure the time taken to load data before optimization\n",
    "    print(\"Before optimization:\")\n",
    "    measure_loading_time(load_data_batch, data)\n",
    "\n",
    "    # Measure the time taken to load data after multi-threading optimization\n",
    "    print(\"After multi-threading optimization:\")\n",
    "    measure_loading_time(load_data_multithreading, batches)\n",
    "\n",
    "    # Measure the time taken to load data after multiprocessing optimization\n",
    "    print(\"After multiprocessing optimization:\")\n",
    "    measure_loading_time(load_data_multiprocessing, batches)\n",
    "\n",
    "# Run the data loading process\n",
    "load_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
